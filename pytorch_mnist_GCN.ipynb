{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_ex_GCN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DDLsPvDoDTv"
      },
      "source": [
        "# Tutorial for creating and training simple Graph Convolutional Networks (GCNs) in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-WdJJjABMDp"
      },
      "source": [
        "# NumPy for data processing and handling\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch for neural networks\n",
        "import torch\n",
        "\n",
        "# MatPlotLib for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoBWwzKwNgV4"
      },
      "source": [
        "# Arbitrarily define the necessarily variables needed to create a Graph Convolutional Network.\n",
        "\n",
        "# Define an adjacency matrix for the graph\n",
        "A_np = np.array([[[[0, 1, 1, 1],\n",
        "                   [1, 0, 1, 1],\n",
        "                   [1, 1, 0, 1],\n",
        "                   [1, 1, 1, 0]]]])\n",
        "\n",
        "# Define a feature matrix (normaly this would come from some dataset and there would be many samples)\n",
        "# Can have arbitrary width but must have the same length as A\n",
        "X_np = np.array([[[[0.5, 0.0],\n",
        "                   [0.0, 1.0],\n",
        "                   [0.3, 0.2],\n",
        "                   [1.0, 0.7]]]])\n",
        "\n",
        "# Define a label (normally this would come from the same dataset as before)\n",
        "y_np = np.array([[0.5]])\n",
        "\n",
        "# Cast numpy arrays as PyTorch tensors\n",
        "A = torch.FloatTensor(A_np)\n",
        "X = torch.FloatTensor(X_np)\n",
        "y = torch.FloatTensor(y_np)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Obvawlb3FN1"
      },
      "source": [
        "# Define our network as a sub class of torch.nn.Module\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        # Number of input nodes must be equal to the width of the feature matrix.\n",
        "        self.l_1 = torch.nn.Linear(2, 128, bias=False)\n",
        "        self.l_2 = torch.nn.Linear(128, 128, bias=False)\n",
        "        self.flat = torch.nn.Flatten()\n",
        "        # Number of output nodes must be equal to the length of the label.\n",
        "        self.l_3 = torch.nn.Linear(4*128, 1)\n",
        "\n",
        "        self.act_1 = torch.nn.ReLU()\n",
        "        self.act_2 = torch.nn.ReLU()\n",
        "        self.act_3 = torch.nn.Tanh()\n",
        "\n",
        "        self.loss_fct = torch.nn.MSELoss()\n",
        "\n",
        "    def forward(self, X, A):\n",
        "        # Graph convolution layer\n",
        "        f = torch.matmul(A, X)\n",
        "        f = self.l_1(f)\n",
        "        f = self.act_1(f)\n",
        "\n",
        "        # Graph convolution layer\n",
        "        f = torch.matmul(A, f)\n",
        "        f = self.l_2(f)\n",
        "        f = self.act_2(f)\n",
        "\n",
        "        # Fully connected layer\n",
        "        f = self.flat(f)\n",
        "        f = self.l_3(f)\n",
        "        f = self.act_3(f)\n",
        "\n",
        "        return f\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        return self.loss_fct(y_pred, y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkRSYzCUJDx9"
      },
      "source": [
        "net = GCN()\n",
        "\n",
        "# Reset epoch count\n",
        "epoch = -1\n",
        "\n",
        "# Array to keep track of the loss after epoch\n",
        "loss_log = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K11jC5ZGa0Aq"
      },
      "source": [
        "#Initialize optimizer\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "n_epoch = 10\n",
        "\n",
        "# Loop over training algorithm for n_epochs\n",
        "for e in range(n_epoch):\n",
        "    # Increase epoch count\n",
        "    epoch += 1\n",
        "\n",
        "    # Initialize variable to keep track of average epoch loss\n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    # Put network in training mode\n",
        "    net.train()\n",
        "\n",
        "    X_th = torch.autograd.Variable(X)\n",
        "    A_th = torch.autograd.Variable(A)\n",
        "    y_true = torch.autograd.Variable(y)\n",
        "\n",
        "    # Set gradients to zero\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Propogate the training data through the network\n",
        "    y_pred = net(X_th, A_th)\n",
        "\n",
        "    # Calculate the loss from the network outputs\n",
        "    loss = net.loss(y_pred, y_true)\n",
        "        \n",
        "    # Perform backpropagation\n",
        "    loss.backward()\n",
        "    # Update weights using backpropagation\n",
        "    optimizer.step()\n",
        "    # Add batch loss to epoch loss\n",
        "    epoch_loss += loss.item()\n",
        "    \n",
        "    # Record the average loss for the epoch\n",
        "    loss_log.append(epoch_loss)\n",
        "\n",
        "    print('\\n' + 'Epoch: ' + str(epoch) + '\\n' + 'Training Loss: ' + str(loss_log[epoch]))\n",
        "\n",
        "print('\\n' + 'Training finished.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5fX0i8K8kcF"
      },
      "source": [
        "# Plot the training and validation loss curves.\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(loss_log)), loss_log, label='Training')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.xlim([0, len(loss_log)-1])\n",
        "plt.ylim([0, 0.03])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8s6fC_HKEpZ"
      },
      "source": [
        "# Save model\n",
        "torch.save(net.state_dict(), './GCN_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO7wltbkKXKE"
      },
      "source": [
        "# Load model\n",
        "loaded_net = GCN()\n",
        "\n",
        "loaded_net.load_state_dict(torch.load('./GCN_model.pkl'))\n",
        "\n",
        "# Put network in inference mode\n",
        "loaded_net.eval()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}