{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_ex_FCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DDLsPvDoDTv"
      },
      "source": [
        "# Tutorial for creating a simple Fully Connected Neural Network (FCNN) in PyTorch and training it on the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-WdJJjABMDp"
      },
      "source": [
        "# Keras for mnist datasat\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# NumPy for data processing and handling\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch for neural networks\n",
        "import torch\n",
        "\n",
        "# MatPlotLib for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnLgh-FlsANl"
      },
      "source": [
        "# Load MNIST dataset from Keras\n",
        "(train_x, train_y), (test_x, test_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoBWwzKwNgV4"
      },
      "source": [
        "# Reshape the data and separate train and validation sets\n",
        "train_inputs = np.reshape(train_x[:-5000], (train_x[:-5000].shape[0], 28*28)) / 255.0\n",
        "val_inputs = np.reshape(train_x[-5000:], (train_x[-5000:].shape[0], 28*28)) / 255.0\n",
        "test_inputs = np.reshape(test_x, (test_x.shape[0], 28*28)) / 255.0\n",
        "train_labels = train_y[:-5000]\n",
        "val_labels = train_y[-5000:]\n",
        "\n",
        "print('Training Inputs shape: ' + str(train_inputs.shape))\n",
        "print('Training Labels shape: ' + str(train_labels.shape))\n",
        "\n",
        "print('Testing Inputs shape: ' + str(test_inputs.shape))\n",
        "print('Testing Labels shape: ' + str(test_labels.shape))\n",
        "\n",
        "print('Validation Inputs shape: ' + str(val_inputs.shape))\n",
        "print('Validation Labels shape: ' + str(val_labels.shape))\n",
        "\n",
        "# Cast numpy arrays as PyTorch tensors\n",
        "x_train = torch.FloatTensor(train_inputs)\n",
        "y_train = torch.LongTensor(train_labels)\n",
        "x_test = torch.FloatTensor(test_inputs)\n",
        "y_test = torch.LongTensor(test_labels)\n",
        "x_val = torch.FloatTensor(val_inputs)\n",
        "y_val = torch.LongTensor(val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv0etipOR6ky"
      },
      "source": [
        "# Visualize a random sample from the MNIST dataset.\n",
        "sample = np.random.randint(train_inputs.shape[0])\n",
        "\n",
        "print(sample, train_labels[sample])\n",
        "plt.imshow(np.reshape(train_inputs[sample], (28, 28)), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Obvawlb3FN1"
      },
      "source": [
        "# Define our network as a sub class of torch.nn.Module\n",
        "class FCNN(torch.nn.Module):\n",
        "    def __init__(self, net_param, p):\n",
        "        super(FCNN, self).__init__()\n",
        "        # Input size must be equal to the length of dataset vectors (28**2 in this case)\n",
        "        self.in_size = net_param['in_size']\n",
        "\n",
        "        # The hidden size can have an arbitrary value\n",
        "        self.hidden_size = net_param['hidden_size']\n",
        "\n",
        "        # The output size must be equal to the number of classes in the dataset (10 in this case) \n",
        "        self.out_size = net_param['out_size']\n",
        "\n",
        "        # Dropout function with probability p\n",
        "        self.dropout = torch.nn.Dropout(p=p)\n",
        "\n",
        "        # Define the network as a sequential set of linear layers, activation functions and dropout \n",
        "        self.network = torch.nn.Sequential(torch.nn.Linear(self.in_size, self.hidden_size),\n",
        "                                           torch.nn.ReLU(),\n",
        "                                           self.dropout,\n",
        "                                           torch.nn.Linear(self.hidden_size, self.out_size))\n",
        "\n",
        "        # Define a loss function for this network. CrossEntropyLoss is a good choice for classification\n",
        "        self.loss_fct = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "    def loss(self, y_pred, y_true):\n",
        "        return self.loss_fct(y_pred, y_true)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkRSYzCUJDx9"
      },
      "source": [
        "# Define the network parameters\n",
        "net_param = {'in_size': 784, 'hidden_size': 128, 'out_size': 10}\n",
        "\n",
        "# Initialize the network\n",
        "net = FCNN(net_param, 0.5)\n",
        "\n",
        "# Reset epoch count\n",
        "epoch = -1\n",
        "\n",
        "# Array to keep track of the loss after epoch\n",
        "loss_log = []\n",
        "val_loss_log = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K11jC5ZGa0Aq"
      },
      "source": [
        "# Initialize optimizer\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Number of training epochs\n",
        "n_epoch = 10\n",
        "\n",
        "# Batch sized used for each update\n",
        "batch_size = 100\n",
        "# Number of batches per epoch\n",
        "n_batchs = x_train.shape[0] // batch_size\n",
        "\n",
        "# Create an array with all the indicies for the training data\n",
        "ind = np.arange(x_train.shape[0])\n",
        "\n",
        "# Loop over training algorithm for n_epochs\n",
        "for e in range(n_epoch):\n",
        "    # Increase epoch count\n",
        "    epoch += 1\n",
        "    # Shuffle training data indices for SGD\n",
        "    shuffled_ind = np.random.permutation(ind)\n",
        "    # Initialize variable to keep track of average epoch loss\n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    # Calculate validation loss\n",
        "    x_val_t = torch.autograd.Variable(x_val)\n",
        "    y_val_true = torch.autograd.Variable(y_val)\n",
        "    y_val_pred = net(x_val_t)\n",
        "    val_loss_log.append(net.loss(y_val_pred, y_val_true).item())\n",
        "    \n",
        "    # Put network in training mode\n",
        "    net.train()\n",
        "\n",
        "    # Loop over training algorithm for each batch in a single epoch\n",
        "    for i in range(n_batchs):\n",
        "        # Collect batch of training data and labels using shuffled indicies\n",
        "        x = torch.autograd.Variable(x_train[shuffled_ind[batch_size*i: batch_size*(i+1)]])\n",
        "        y_true = torch.autograd.Variable(y_train[shuffled_ind[batch_size*i: batch_size*(i+1)]])\n",
        "\n",
        "        # Set gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Propogate the training data through the network\n",
        "        y_pred = net(x)\n",
        "\n",
        "        # Calculate the loss from the network outputs\n",
        "        loss = net.loss(y_pred, y_true)\n",
        "        \n",
        "        # Perform backpropagation\n",
        "        loss.backward()\n",
        "        # Update weights using backpropagation\n",
        "        optimizer.step()\n",
        "        # Add batch loss to epoch loss\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # Record the average loss for the epoch\n",
        "    loss_log.append(epoch_loss / n_batchs)\n",
        "    \n",
        "    print('\\n' + 'Epoch: ' + str(epoch) + '\\n' + 'Training Loss: ' + str(loss_log[epoch]) + '\\n' + 'Validation Loss: ' + str(val_loss_log[epoch]))\n",
        "\n",
        "print('\\n' + 'Training finished.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q-wQiLh6mEI"
      },
      "source": [
        "# Put network in inference mode\n",
        "net.eval()\n",
        "\n",
        "# Calculate training loss\n",
        "x = torch.autograd.Variable(x_train)\n",
        "y_true = torch.autograd.Variable(y_train)\n",
        "y_pred = net(x)\n",
        "epoch_loss = net.loss(y_pred, y_true).item()\n",
        "\n",
        "# Calculate validation loss\n",
        "x_val_t = torch.autograd.Variable(x_val)\n",
        "y_val_true = torch.autograd.Variable(y_val)\n",
        "y_val_pred = net(x_val)\n",
        "val_loss = net.loss(y_val_pred, y_val).item()\n",
        "\n",
        "# Calculate test loss\n",
        "x_test_t = torch.autograd.Variable(x_test)\n",
        "y_test_true = torch.autograd.Variable(y_test)\n",
        "y_test_pred = net(x_test_t)\n",
        "test_loss = net.loss(y_test_pred, y_test).item()\n",
        "\n",
        "# Calculate model accuracy\n",
        "train_values, train_indices = torch.max(y_pred, 1)\n",
        "train_correct = y_true[train_indices == y_true].shape[0]\n",
        "\n",
        "val_values, val_indices = torch.max(y_val_pred, 1)\n",
        "val_correct = y_val_true[val_indices == y_val_true].shape[0]\n",
        "\n",
        "test_values, test_indices = torch.max(y_test_pred, 1)\n",
        "test_correct = y_test_true[test_indices == y_test_true].shape[0]\n",
        "\n",
        "# Record the average loss for the epoch\n",
        "print('Epoch: %d \\n' % (epoch+1))\n",
        "print('  Training Loss: %.4f, Accuracy: %.4f' % (epoch_loss, train_correct / y_true.shape[0]))\n",
        "print('Validation Loss: %.4f, Accuracy: %.4f' % (val_loss, val_correct / y_val_true.shape[0]))\n",
        "print('      Test Loss: %.4f, Accuracy: %.4f' % (test_loss, test_correct / y_test_true.shape[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5fX0i8K8kcF"
      },
      "source": [
        "# Plot the training and validation loss curves.\n",
        "plt.figure()\n",
        "plt.plot(np.arange(len(loss_log)), loss_log, label='Training')\n",
        "plt.plot(np.arange(len(val_loss_log)), val_loss_log, label='Validation')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Cross Entropy Loss')\n",
        "plt.xlim([0, len(loss_log)-1])\n",
        "plt.ylim([0, 3])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8s6fC_HKEpZ"
      },
      "source": [
        "# Save model\n",
        "torch.save(net.state_dict(), './mnist_model.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO7wltbkKXKE"
      },
      "source": [
        "# Load model\n",
        "net_param = {'in_size': 784, 'hidden_size': 128, 'out_size': 10}\n",
        "\n",
        "loaded_net = FCNN(net_param, 0.5)\n",
        "\n",
        "loaded_net.load_state_dict(torch.load('./mnist_model.pkl'))\n",
        "\n",
        "# Put network in inference mode\n",
        "loaded_net.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3xSRTZ7JbBw"
      },
      "source": [
        "# Use the trained model to make predictions on the testing dataset\n",
        "sample = np.random.randint(test_inputs.shape[0])\n",
        "\n",
        "x_sample = torch.autograd.Variable(x_test[sample])\n",
        "y_sample_true = torch.autograd.Variable(y_test[sample])\n",
        "value, y_sample_pred = torch.max(loaded_net(x_sample), 0)\n",
        "print('     True Label: %d' % (y_sample_true))\n",
        "print('Predicted Label: %d' % (y_sample_pred))\n",
        "\n",
        "plt.imshow(np.reshape(test_inputs[sample], (28, 28)), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}